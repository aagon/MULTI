#+TITLE : Prise de notes TP 4I106 MULTI
#+PROPERTY: header-args :mkdirp yes
#+STARTUP: inlineimages

Alain Greiner (alain.greiner@lip6.fr)

* TP 1 : 30/01/2020

Pour ce premier TP, on va d'intéresser au bus, qui est un bon exemple d'automate, et en particulier au Pi-bus, qui suit les règles suivantes :

Le pi-bus est un bus multimaître synchrone.

Deux types de composants matériels qui doivent communiquer entre eux :
- les maîtres sont par exemple les coeurs (et leurs caches privés)
- les cibles, comme la ram, la rom, le tty

La fonction du bus, c'est l'aiguillage et le routage.

On a avant toutes choses un bus de commandes, qui se décline en trois nappes de fils, ADDR (30 bits, puisqu'on ne ramène que des mots), OPC (4 bits), READ (1 bit).

Les seuls qui écrivent sur ce bus de commandes, ce sont les maîtres (et on peut d'ailleurs les définir comme ça).

On a un deuxième bus, le bus de réponses. Ce bus est unique, il s'appelle ACK (2 bits, car on a 3 réponses possibles READY, WAIT, ERROR) et seules les cibles peuvent écrire sur ce bus (on peut d'ailleurs les définir comme ça).

On a un bus de données qui est utilisé par les maîtres et les cibles (en effet, un maître veut pouvoir lire comme écrire).

On a un fil req et un fil gnt par maître qui arrive au BCU, bus control unit. (un des rarissimes automates non-Moore, donc Mealy général).

On peut spécifier un protocole du bus par son chronogramme :

- Phase d'allocation : la demande du bus et la réponse doivent avoir lieu dans le même cycle d'horloge.

- Phase d'adresse : les signaux Addr, lock, etc...

- Phase de donnée : D et ACK 

L'allocation d'un nouveau maître peut se faire pendant le dernier (LOCK est à 0) cycle de la transaction n à condition que la valeur envoyée soit RDY ou ERROR.

** Question C1

*** Noeud IDLE

F : C(SEL)
A : C(READ).DELAY.SEL.ADR_OK
B : C(READ).C(DELAY).SEL.ADR_OK
C : READ.C(DELAY).SEL.ADR_OK
D : READ.DELAY.SEL.ADR_OK
E : C(ADR_OK).SEL

On a l'orthogonalité sur ce noeud :

F d'intersection nulle avec tous les autres (car SEL.C(SEL) = 0).
On se permet donc de l'éliminer.

E est d'intersection nulle avec tous les autres (car ADR_OK.C(ADR_OK) = 0)
On se permet donc de l'éliminer.

A est d'intersection nulle avec C et D (car READ.C(READ) = 0)
B est d'intersection nulle avec C et D (car READ.C(READ) = 0)

A est d'intersection nulle avec B (car DELAY.C(DELAY) = 0)

C est d'intersection nulle avec A et B (car READ.C(READ) = 0)
D est d'intersection nulle avec A et B (car READ.C(READ) = 0)
On a montré que A et B étaient d'intersection nulle avec tous les autres, et entre eux.
On peut donc éliminer A et B.

C est d'intersection nulle avec D (car DELAY.C(DELAY)).
On a montré que C et D étaient d'intersection nulle avec tous les autres, et entre eux.
On peut donc éliminer C et D.

On a bien l'orthogonalité pour IDLE.

La complétude :

A + B = C(READ).DELAY.SEL.ADR_OK + C(READ).C(DELAY).SEL.ADR_OK
A + B = C(READ).SEL.ADR_OK

C + D = READ.C(DELAY).SEL.ADR_OK + READ.DELAY.SEL.ADR_OK
C + D = READ.SEL.ADR_OK

Donc :

A + B + C + D = C(READ).SEL.ADR_OK + READ.SEL.ADR_OK
A + B + C + D = SEL.ADR_OK

Donc :

A + B + C + D + E = SEL.ADR_OK + SEL.C(ADR_OK)
A + B + C + D + E = SEL

Donc :

A + B + C + D + E + F = SEL + C(SEL) = 1

On a bien la somme de toutes les conditions de transition égale à 1.

*** Noeud R_WAIT

V : GO
V' : C(GO)

L'orthogonalité et la complétude sont triviale.

*** Noeud W_WAIT

U : GO
U' : C(GO)

L'orthogonalité et la complétude sont triviale.

*** Noeud R_OK

R : C(ADR_OK).SEL
S : ADR_OK.SEL
T : C(SEL)

L'orthogonalité est évidente :

T.R = 0
T.S = 0
R.S = 0

La complétude :

R + S = C(ADR_OK).SEL + ADR_OK.SEL
R + S = SEL

R + S + T = SEL + C(SEL) = 1

On a bien la complétude.

*** Noeud W_OK

X : ADR_OK.SEL
Y : C(ADR_OK).SEL
Z : C(SEL)

La démonstration de l'orthogonalité et de la complétude est symétrique à celle du noeud R_OK.

*** Noeud ERROR

On n'a pas de transition qui nous fait rester dans l'état ERROR.

On admet donc qu'on va dans l'état IDLE de manière inconditionnée.

G : 1

** Question C2

*** Noeud IDLE

Dans ces état, le matériel n'écrit pas sur le bus :

On a donc ACK_EN = 0
La valeur de ACK_VALUE n'a pas d'importance, on lui met NULL
On a DT_EN = 0 puisqu'on écrit pas sur le bus de données.
On n'écrit ni ne lit dans la mémoire, donc MEM_CMD est à NOP.

*** Noeud R_WAIT

Dans cet état, on écrit sur le bus ACK la valeur WAIT. On a donc besoin de mettre le signal ACK_VALUE à WAIT, et ACK_EN à 1.

On n'écrit pas sur le bus de données, puisque celles-ci ne sont pas encore prêtes (on envoie WAIT pour une raison). Donc DT_EN est à 0.

Le maître a demandé d'accéder à une zone de la mémoire en lecture, c'est donc la commande READ qu'on envoie vers la mémoire.

*** Noeud R_OK

Dans cet état, on écrit sur le bus ACK la valeur READY. On a donc besoin de mettre de signal ACK_VALUE à READY, et ACK_EN à 1.

On écrit sur le bus de données, puisque les données sont prêtes.

La commande à mettre dans MEM_CMD est ambigüe :
- Si on admet que la mémoire n'est pas capable d'obtenir une donnée dans le même cycle pendant lequel on lui a demandé, on n'aura jamais READ en sortie sur MEM_CMD pendant qu'on envoie la donnée sur le bus.
- Par contre, si on admet qu'elle en est capable, on a dans le même cycle READ sur MEM_CMD, puis dès la réception de la donnée (dans le même cycle donc) READY sur ACK_VALUE.

La valeur de ce fil en sortie dépend du paramètre L (NOP s'il est non nul, READ s'il est nul). (attention, on ne vient pas de transformer cette machine en machine de Mealy : L est un paramètre, choisi au démarrage de la machine, qui ne change plus ensuite.)

*** Noeud W_WAIT

Dans cet état, on écrit sur le bus ACK la valeur WAIT. On a donc besoin de mettre le signal ACK_VALUE à READY, et ACK_EN à 1.

On n'écrit pas sur le bus de données, on a reçu une instruction d'écriture, donc DT_EN est à 0.

Le maître a demandé d'accéder à une zone de la mémoire en écriture, c'est donc la commande WRITE qu'on envoie vers la mémoire.

*** Noeud W_OK

Dans cet état, on écrit sur le bus ACK la valeur READY. On a donc besoin de mettre de signal ACK_VALUE à READY, et ACK_EN à 1.

On n'écrit pas sur le bus de données, on a reçu une instruction d'écriture, donc DT_EN est à 0.

Pour la même raison que pour R_OK, la valeur de MEM_CMD dépendraa du paramètre L

*** Noeud ERROR

Dans cet état, on écrit sur le bus ACK pour signaler l'erreur.

On n'écrit pas sur le bus de données, on n'a rien à y écrire, ni aucune commande non plus à envoyer à la mémoire.

*** Résumé

|        | ACK_EN | ACK_VALUE | DT_EN | MEM_CMD                   |
|--------+--------+-----------+-------+---------------------------|
| IDLE   |      0 | NULL      |     0 | NOP                       |
| R_WAIT |      1 | WAIT      |     0 | READ                      |
| R_OK   |      1 | READY     |     1 | NOP (si !L), READ (si L)  |
| W_WAIT |      1 | WAIT      |     0 | WRITE                     |
| W_OK   |      1 | READY     |     0 | NOP (si !L), WRITE (si L) |
| ERROR  |      1 | ERROR     |     0 | NOP                       |


A priori, on n'a écrit sur les bus ACK comme DT qu'au moment où on avait le droit de le faire. En effet, si on se rappelle le chronogramme du PIBUS, les différents états : R_WAIT R_OK W_WAIT W_OK ERROR n'arrivent qu'après une demande du maître. On a donc le bus réservé pour la réponse (donc aucun problème pour le bus ACK), et éventuellement le bus DT réservé si on a une donnée à transmettre.

Donc notre fonction de génération ne créé pas de court-circuits.

** Question D1

*** Noeud INIT

On passe de INIT à RAM_REQ de manière inconditionnée.

Donc A = 1

*** Noeud RAM_REQ

On passe de RAM_REQ à RAM_A0 (demande de la première adresse) seulement si le bus est alloué. On a donc

B = GNT, et donc B' = C(GNT)

*** Noeud RAM_A0

On passe de RAM_A0 à RAM_A1_D0 (attente de la première donnée et demande de la deuxième adresse) de manière inconditionnée.

Même si la mémoire fait attendre le maître, on demande quand même la prochaine adresse.

Donc C = 1

*** Noeud RAM_A1_D0

Cet état signifie très exactement : *attente* de la première donnée et demande de la deuxième adresse.

La consigne précise :

#+BEGIN_QUOTE
Dans le cas des transactions de type rafale, on utilise une technique de pipe-line, pour effectuer, dans le même cycle et sur deux nappes de fils séparées, le transfert de l'adresse (i+1), en même temps que le transfert de la donnée (i).
#+END_QUOTE

Moi, le maître, je n'ai le droit de demander l'adresse i+1 que si je reçois READY sur le bus ACK pour ma demande de l'adresse i.

Donc

D = RDY et D' = C(RDY)

*** Noeud RAM_A2_D1

De même :

E = RDY et E' = C(RDY)

*** Noeud RAM_A3_D2

De même :

F = RDY et F' = C(RDY)

*** Noeud RAM_D3

De même :

G = RDY et G' = C(RDY)

*** Noeud W_REQ

Dans cet état, on demande l'accès au bus pour écrire dans le tty.

On ne passe dans l'état W_AD que si le bus nous a été donné, donc :

H = GNT et H' = C(GNT)

*** Noeud W_AD

Dans cet état, on envoie une instruction d'écriture sur le bus, à destination du tty.

On ne demande rien dans cet état, on en sort de manière inconditionnée.

Donc I = 1

*** Noeud W_DT

Dans cet état, le maître envoie le caractère et doit vérifier :
- Que le caractère qu'il a transmis est bien arrivé et a bien été traité.
- Qu'il a bien envoyé tous les caractères.

S'il a envoyé tous les caractères, il doit passer dans sa boucle d'attente de saisie du clavier.

Sinon, il doit envoyer le caractère suivant. Et pour cela, il doit demander le bus.

Donc K = RDY.LAST et L = RDY.C(LAST) et J = C(RDY)

On a bien la complétude et l'orthogonalité.

*** Noeud STS_REQ

Dans cet état, le maître veut vérifier la valeur du registre status du tty pour savoir si quelqu'un a écrit dans le terminal.

Pour lire cette valeur, il doit obtenir le bus.

Donc M = GNT et M' = C(GNT)

*** Noeud STS_AD

Dans cet état, le maître envoie l'adresse du registre status du tty, il ne demande rien, il sort de cet état de manière inconditionnée.

Donc N = 1

*** Noeud STS_DT

Dans cet état, le maître doit vérifier :
- Qu'il a bien reçu le contenu du registre status du tty.
- Que la valeur de ce registre est bien non nulle, auquel cas il va demander de lire le registre keybuf du terminal.

Donc O = C(RDY) et P = RDY.C(NUL) et Q = RDY.NUL

On a bien la complétude et l'orthogonalité.

*** Noeud BUF_REQ

Dans cet état, le maître veut lire la valeur du registre keybuf du terminal.

Pour ça, il doit obtenir le bus.

Donc R = GNT et R' = C(GNT)

*** Noeud BUF_AD

Dans cet état, le maître envoie une demande en lecture vers le terminal, il n'attend rien.

On sort de cet état de manière inconditionnée.

Donc S = 1

*** Noeud BUF_DT

Dans cet état, le maître doit simplement attendre la donnée du registre keybuf du terminal.

Donc T = RDY et T' = C(RDY)

** Question D2

*** Noeud INIT

Dans cet état, le maître ne demande rien, n'a pas le bus de commandes ni le bus de données.

On a donc C(REQ), C(CMD_EN), C(DT_EN).

Les signaux ADR_VALUE, READ_VALUE, et LOCK_VALUE ne sont pas applicables, ils ne sont pas envoyés.

*** Noeud RAM_REQ

Dans cet état, le maître demande le bus, mais il ne l'a pas encore. Il n'a pas le droit d'écrire, ni sur le bus de données, ni sur le bus de commandes.

On a donc REQ, C(CMD_EN), C(DT_EN).

Les signaux ADR_VALUE, READ_VALUE, et LOCK_VALUE ne sont toujours pas applicables, ils ne sont pas envoyés.

*** Noeud RAM_A0

Dans cet état, le maître a le bus, il demande l'adresse RAM_BASE.

Le signal REQ passe à 0, parce que la consigne spécifie que celui-ci est utilisé seulement pour demander le bus, pas pour le garder (c'est le signal LOCK_VALUE qui remplit ce rôle).

On envoie une demande, il faut donc autoriser l'émission sur le bus de commandes, donc le signal CMD_EN est activé.

Il s'agit d'une requête en lecture, donc READ_VALUE est à 1.

Il s'agit d'une demande rafale, et cette demande n'est pas la dernière de la rafale. On mettra donc le signal LOCK_VALUE.

On n'écrit pas sur le bus de données, donc DT_EN est à 0.

*** Noeud RAM_A1_D0

Dans cet état, le maître a le bus, il demande l'adresse RAM_BASE+4.

Le signal REQ passe à 0, parce que la consigne spécifie que celui-ci est utilisé seulement pour demander le bus, pas pour le garder (c'est le signal LOCK_VALUE qui remplit ce rôle).

On envoie une demande, il faut donc autoriser l'émission sur le bus de commandes, donc le signal CMD_EN est activé.

Il s'agit d'une requête en lecture, donc READ_VALUE est à 1.

Il s'agit d'une demande rafale, et cette demande n'est pas la dernière de la rafale. On mettra donc le signal LOCK_VALUE.

On n'écrit pas sur le bus de données, donc DT_EN est à 0.

*** Noeud RAM_A2_D1

Pareil que l'état précédent, on prendra bien garde à changer la valeur de la variable ADR_VALUE.

*** Noeud RAM_A3_D2

Pareil que l'état précédent, on prendra bien garde à changer la valeur de la variable ADR_VALUE.

On signalera aussi que la commande est la dernière de la rafale en mettant le signal LOCK_VALUE à 0.

*** Noeud RAM_D3

Dans cet état, le maître n'envoie plus de commandes, donc ADR_VALUE et READ_VALUE et LOCK_VALUE ne sont plus applicables, et CMD_EN est à 0.

On ne demande pas le bus, donc REQ est à 0.

On n'écrit pas sur le bus de données, donc DT_EN est à 0.

*** Noeud W_REQ

Dans cet état, le maître demande le bus, on met donc REQ à 1.

Il ne l'a pas reçu, donc il n'a pas le droit d'écrire sur le bus de commandes. Donc CMD_EN est à 0, et ADR_VALUE, READ_VALUE et LOCK_VALUE ne sont pas applicables.

On n'écrit pas sur le bus de données non plus, donc DT_EN est à 0.

*** Noeud W_AD

Dans cet état, le maître a obtenu le bus, il lance une requête d'écriture simple sur le bus à destination de l'adresse TTY_BASE.

On a donc REQ à 0, CMD_EN à 1, ADR_VALUE à TTY_BASE, READ_VALUE à 0, LOCK_VALUE à 0.

Ici, on a une ambigüité : le maître envoie-t-il les données dans cet état, ou dans l'état suivant ? Le modèle fourni par soclib semble pencher pour la deuxième option, même s'il n'est nulle part question de cycle de décalage entre la requête d'écriture et l'envoi effectif des données.

Le chronogramme (tp1_chronogramme.png) semble aussi pencher pour la deuxième option.

On met donc DT_EN à 0

*** Noeud W_DT

Dans cet état, le maître envoie les données du caractère sur le bus de données, on met donc DT_EN à 1.

Sinon, il n'envoie pas de commandes, ni ne demande le bus.

*** Noeud STS_REQ

Dans cet état, le maître veut obtenir le bus. On a donc REQ à 1.

Puisqu'il ne l'a pas, il n'écrit ni sur le bus de commandes, ni sur le bus de données.

*** Noeud STS_AD

Dans cet état, le maître envoie une requête en lecture simple vers l'adresse TTY_BASE+4. Il n'utilise pas le bus de données.

*** Noeud STS_DT

Dans cet état, le maître reçoit la réponse du terminal. Il ne demande pas le bus, il n'envoie pas de commandes, ni de données.

*** Noeud BUF_REQ

Dans cet état, le maître veut obtenir le bus. On donc REQ à 1.

Puisqu'il ne l'a pas, il n'écrit ni sur le bus de commandes, ni sur le bus de données.

*** Noeud BUF_AD

Dans cet état, le maître a obtenu le bus, il lance une requête simple en lecture vers l'adresse TTY_BASE+8. Il n'utilise pas le bus de données.

*** Noeud BUF_DT

Dans cet état, le maître attend la réponse du terminal. Il n'utilise aucun bus.

*** Résumé

|           | REQ | CMD_EN | ADR_VALUE   | READ_VALUE | LOCK_VALUE | DT_EN |
|-----------+-----+--------+-------------+------------+------------+-------|
| INIT      |   0 |      0 | NULL        | NULL       | NULL       |     0 |
| RAM_REQ   |   1 |      0 | NULL        | NULL       | NULL       |     0 |
| RAM_A0    |   0 |      1 | RAM_BASE    | 1          | 1          |     0 |
| RAM_A1_D0 |   0 |      1 | RAM_BASE+4  | 1          | 1          |     0 |
| RAM_A2_D1 |   0 |      1 | RAM_BASE+8  | 1          | 1          |     0 |
| RAM_A3_D2 |   0 |      1 | RAM_BASE+12 | 1          | 0          |     0 |
| RAM_D3    |   0 |      0 | NULL        | NULL       | NULL       |     0 |
| W_REQ     |   1 |      0 | NULL        | NULL       | NULL       |     0 |
| W_AD      |   0 |      1 | TTY_BASE    | 0          | 0          |     0 |
| W_DT      |   0 |      0 | NULL        | NULL       | NULL       |     1 |
| STS_REQ   |   1 |      0 | NULL        | NULL       | NULL       |     0 |
| STS_AD    |   0 |      1 | TTY_BASE+4  | 1          | 0          |     0 |
| STS_DT    |   0 |      0 | NULL        | NULL       | NULL       |     0 |
| BUF_REQ   |   1 |      0 | NULL        | NULL       | NULL       |     0 |
| BUF_AD    |   0 |      1 | TTY_BASE+8  | 1          | 0          |     0 |
| BUF_DT    |   0 |      0 | NULL        | NULL       | NULL       |     0 |

On a tenu à distinguer NULL et 0 pour distinguer les cas où le signal était effectivement signifiant. Dans les fait, NULL peut prendre n'importe quelle valeur, le signal n'est pas transmis. On imagine qu'il prend la valeur 0.

** Question E1

*** Noeud IDLE

On reste dans l'état IDLE seulement si personne ne demande le bus.

Donc X' = C(REQ) et X = REQ

On a de manière évidente l'orthogonalité et la complétude.

*** Noeud AD

Dans cet état, le bus a été alloué à un maître, et c'est la première commande.

La première commande est en même temps la dernière commande si, et seulement si, LOCK est à 0. Sinon, on est la première commande d'une rafale, et donc on va dans l'état DTAD.

Donc Y = LOCK et Y' = C(LOCK)

On a de manière évidente l'orthogonalité et la complétude.

*** Noeud DTAD

Dans cet état, le bus a été alloué à un maitre, et on est au milieu d'un transaction rafale : CMD(i) / RSP(i-1).

On ne sort de cet état que si :
- la commande envoyée est bien la dernière
- On a bien reçu soit READY, soit ERROR de la cible.

Donc Z = C(WAIT).C(LOCK) et Z' = WAIT + LOCK

On a de manière évidente l'orthogonalité et la complétude.

*** Noeud DT

On ne sort de cet état que si la réponse de la cible est READY ou ERROR.

Donc J = WAIT

On ne retourne dans l'état IDLE que si personne n'a demandé le bus.

Donc K = C(WAIT).C(REQ)

On ne retourne dans l'état AD que si quelqu'un a demandé le bus.

Donc L = C(WAIT).REQ

On a l'orthogonalité et la complétude par construction.

** Question E2

*** Noeud IDLE

On se rappelle ici le fait que cet automate est un automate de Mealy. Le BCU est censé répondre à la requête du maître dans le même cycle.

Le signal GNT est donc activé à la suite de la réception du signal REQ.

Le maître n'a encore sélectionné personne, les signaux de sélection sont à 0.

*** Noeud AD

Dans cet état, le maître a sélectionné un maître et une cible. Dans ce PIBUS simplifié, on a seulement deux cibles possibles, la RAM et le tty.

On active bien entendu qu'un seul des deux signaux SEL0 et SEL1, sous peine de court-circuit.

On active SEL0 si les bits de poids fort correspondent à une adresse de la RAM, SEL1 sinon.

On n'a pas besoin d'activer le signal GNT, le bus a déjà été attribué.

*** Noeud AD/DT

Pareil qu'au noeud précédent.

*** Noeud DT

Dans ce noeud, le bus a été alloué à un maître, et c'est la réponse à la dernière commande.

On n'a pas de commande, donc SEL0 et SEL1 sont à 0.

Si la réponse de la cible est WAIT, on reste dans cet état, on continue à attendre.

Si la réponse de la cible n'est pas WAIT, c'est que le maître courant a fini sa demande (qu'elle soit valable ou non). On peut donc déjà attribuer le bus à un autre maître (ou au même), pour qu'il puisse faire sa commande au prochain cycle. Si le maître requiert le bus (signal REQ), on le lui donne (signal GNT).

*** Résumé

|       | GNT         | SEL0          | SEL1          |
|-------+-------------+---------------+---------------|
| IDLE  | REQ         | 0             | 0             |
| AD    | 0           | DEC(A) == RAM | DEC(A) != RAM |
| DT/AD | 0           | DEC(A) == RAM | DEC(A) != RAM |
| DT    | REQ.C(WAIT) | 0             | 0             |

** Question E3

Comme on l'a déjà expliqué, les contraintes se limitent strictement à :
- on doit laisser un cycle entre la commande d'un maître et la commande d'un autre maître
- le bcu doit répondre au maître dans le même cycle que la demande

Donc, lors de la réponse à la dernière commande d'un maître, la dernière fois que le maître en question a parlé, c'était au cycle précédent. On peut donc se permettre de faire parler un autre maître au cycle suivant. Pour pouvoir faire parler un maître au cycle suivant, il faut lui accorder le bus là maintenant.

Donc, on alloue le maître non seulement dans l'état IDLE, mais aussi dans l'état DT, pour gagner un cycle. 

** Question F1

Instanciation des deux matériels manquants :

#+BEGIN_SRC c++
  PibusSimpleMaster		master	("master", SEG_RAM_BASE, SEG_TTY_BASE);
  PibusSimpleRam		ram	("ram"  , 0, segtable, ram_latency, loader);
#+END_SRC

Connexion des deux matériels manquants :

Commençons par la ram :
- on connecte le signal d'horloge, le signal de reset, et le signal de "tout" (on ne sait pas ce qu'il fait)

#+BEGIN_SRC c++
  ram.p_ck(signal_ck);
  ram.p_resetn(signal_resetn);
  ram.p_tout(signal_pi_tout);
#+END_SRC

- on connecte le signal de sélection (SEL0) :

#+BEGIN_SRC c++
  ram.p_sel(signal_sel_ram);
#+END_SRC

- On connecte le signal d'adresse, d'opcode, de read, de data, de ack :

#+BEGIN_SRC c++
  ram.p_a(signal_pi_a);
  ram.p_read(signal_pi_read);
  ram.p_opc(signal_pi_opc);
  ram.p_ack(signal_pi_ack);
  ram.p_d(signal_pi_d);
#+END_SRC

Ensuite, le maître :
- On commence toujours par le signal d'horloge, de reset, et de tout :

#+BEGIN_SRC c++
  master.p_ck(signal_ck);
  master.p_resetn(signal_resetn);
  master.p_tout(signal_pi_tout);
#+END_SRC

- On connecte le signal de req, de gnt, de lock :

#+BEGIN_SRC c++
  master.p_req(signal_req_master);
  master.p_gnt(signal_gnt_master);
  master.p_lock(signal_pi_lock);
#+END_SRC

- On connecte le signal de addr, opc, read, data, et ack :

#+BEGIN_SRC c++
  master.p_a(signal_pi_a);
  master.p_opc(signal_pi_opc);
  master.p_read(signal_pi_read);
  master.p_d(signal_pi_d);
  master.p_ack(signal_pi_ack);
#+END_SRC

** Question F2

Ajout du segment du tty :

#+BEGIN_SRC c++
  segtable.addSegment("seg_tty", SEG_TTY_BASE, 0x00000010, 1, false);
#+END_SRC

On lui donne le nom "seg_tty", on le fait commencer à SEG_TTY_BASE, on sait par la consigne qu'il occupe 16 octets (4 registres d'un mot chacun), l'identifiant de la cible tty est 1, et on désactive le cache.

** Question F3

Comment est initialisée la chaîne de caractères "Hello World!" dans la mémoire ?

Le constructeur de l'objet PibusSimpleRam prend en dernier argument une référence vers un objet Loader.

L'objet Loader qu'on lui a passé en paramètre est loader, qu'on a instancié trois lignes plus haut :

Le constructeur de cet objet loader prend en paramètre une chaîne de caractères, probablement parsée :
- string_file : un cheminom de fichier qui contient les données à charger
- 0x10000000 : l'adresse à laquelle charger ces données
- D : un flag, apparemment

** Question G1

En exécutant la commande :

#+BEGIN_SRC shell
  time ./simul.x -NCYCLES 1000000
#+END_SRC

On obtient :

- real    0m3.993s
- user    0m1.578s
- sys     0m1.146s


Donc 1000000 de cycles simulés en 4 secondes, soient 250000 cycles par secondes, soit 250 kHz.

La condition selon laquelle SystemC ne doit pas être pire que 1000 fois moins rapide que le matériel est à peu près tenue, si on suppose un matériel simulé à 250 MHz.

** Question G2

Combien y-a-t-il de cycles d'attente dans les états de l'automate du composant maître où celui-ci demande au BCU l'allocation du bus ? Expliquez ce comportement.

On admet que la question signifie : combien y a-t-il de cycles d'attente entre la demande du bus par le maître et son allocation ?

Il n'y a aucun cycle d'attente entre la demande du bus et son allocation : on a l'activation du signal REQ, qui demande le bus, et du signal GNT, qui l'accorde, dans les mêmes cycles.

Ce comportement est voulu. On veut pouvoir répondre au maître tout de suite. Cette chose est rendus possible par le fait que le BCU est un automate de Mealy : son signal GNT peut être activé de manière asynchrone aux fronts d'horloge.

** Question G3

Combien y-a-t-il de cycles d'attente dans les états de l'automate du composant maître ou celui-ci attend la réponse de la RAM ? Expliquez ce comportement.

On admet que la question signifie :

Combien faut-il de cycles entre l'arrivée de la demande du maître à la RAM et le passage de la RAM dans l'état READ_OK (qui signifie que la RAM envoie les données demandées sur le bus) ?

Avec les paramètres qu'on a choisi, on a deux cycles d'attente.

Regardons pour cela les cycles 1, 2, 3 et 4.

(Pour une raison inexpliquée, le maître ne commence pas dans l'état INIT, mais directement dans l'état RAM_A0.)

#+BEGIN_QUOTE
,*******  cycle = 1 *******
bcu : fsm = AD | selected target = 0
master : state = RAM_A0
ram : IDLE
tty : IDLE   keyboard status[0] = 0   display status[0] = 0
req     = 0
gnt     = 0
sel_ram = 1
sel_tty = 0
avalid  = 1
read    = 1
lock    = 1
address = 0x10000000
ack     = 0
data    = 0
,*******  cycle = 2 *******
bcu : fsm = DTAD | selected target = 0
master : state = RAM_A1_D0
ram : READ_WAIT
tty : IDLE   keyboard status[0] = 0   display status[0] = 0
req     = 0
gnt     = 0
sel_ram = 1
sel_tty = 0
avalid  = 1
read    = 1
lock    = 1
address = 0x10000004
ack     = 0
data    = 0
,*******  cycle = 3 *******
bcu : fsm = DTAD | selected target = 0
master : state = RAM_A1_D0
ram : READ_WAIT
tty : IDLE   keyboard status[0] = 0   display status[0] = 0
req     = 0
gnt     = 0
sel_ram = 1
sel_tty = 0
avalid  = 1
read    = 1
lock    = 1
address = 0x10000004
ack     = 0
data    = 0
,*******  cycle = 4 *******
bcu : fsm = DTAD | selected target = 0
master : state = RAM_A1_D0
ram : READ_OK
tty : IDLE   keyboard status[0] = 0   display status[0] = 0
req     = 0
gnt     = 0
sel_ram = 1
sel_tty = 0
avalid  = 1
read    = 1
lock    = 1
address = 0x10000004
ack     = 0x2
data    = 0x6c6c6548
#+END_QUOTE

Le cycle 1 est la demande du maître. Celle-ci arrive à la fin du cycle 1, la RAM sort de l'état IDLE avec le front montant du cycle 2.

La RAM reste dans l'état READ_WAIT jusqu'à la fin du cycle 3, soient deux cycles entiers.

On a donc deux cycles d'attente pour la première demande, ce qui correspond bien au paramètre ram_latency qu'on a choisi. (pas d'attente en revanche pour les demandes suivantes de la rafale, ce qui correspond à notre modélisation de la RAM)

** Question G4

On admet que la question signifie :

Combien faut-il de cycles, *depuis un état initial INIT du maître*, pour afficher un caractère sur le composant PIBUS_MULTI_TTY ?

On commence donc par se placer dans le premier état INIT du maître (dont l'index du cycle n'est pas déterministe, il dépend en fait du temps qu'on a fait tourner le maître à attendre notre input au clavier).

Il se trouve que dans ma trace, ce premier état initial INIT est au cycle 9389. On recherche donc à partir de ce cycle-là le premier état DISPLAY du TTY, avec 0x48 ('H') en data.

C'est le cycle 9400.

Il faut donc 9400 - 9389 = 11 cycles pour afficher un caractère dans le composant PIBUS_MULTI_TTY depuis l'état inital INIT du maître, étant donné les valeurs de latence de la RAM données en paramètres (soit 2 dans notre cas, variable ram_latency que nous n'avons pas modifié).

** Question G5

Comme on l'a déjà dit, le maître commence directement dans l'état RAM_A0 pour une raison inexpliquée.

Le chronogramme tiendra compte de cet état de choses, et commencera aussi dans cet état-là.

Ci-joint donc un chronogramme des cycles 1 à 20 compris :

[[./TP1/chronogramme.png][Chronogramme]]


On s'est permis de spécifier à certains endroits un signal XXX pour "don't care". On voulait en fait faire remarquer que personne n'écrivait à ce moment-là. Laisser la valeur résiduelle des cycles précédents aurait fonctionné aussi, mais on aurait eu plus de mal à faire la différence entre un signal effectivement envoyé et un signal résiduel dont il ne faut pas tenir compte.


* TP 2 : 07/02/2020

** Question C1

On a direct mapping, soit icache_ways = 1

On a 16 octets par ligne de cache, soit 4 mots, donc icache_words = 4

1024 / 16, soient 64 lignes, donc icache_sets = 64

De même pour les caches de données.

** Question C2

Il faut pouvoir garantir que la machine rebootera après un arrêt intempestif.

Pour que notre automate soit déterministe, il faut qu'il ait un unique état initial connu et constant.

Cet état initial est donné par le contenu du segment seg_reset.

Il faut absolument que ce segment mappe vers une zone de la mémoire en lecture seule.

** Question C3

Le segment seg_tty doit être non cachable, parce que les caractères affichés dans le terminal doivent toujours correspondre effectivement à ce que le processeur connaît.

Le cache permet que ces deux valeurs soient différentes, même transitoirement, et c'est inacceptable.

** Question C4

Les segments protégés sont :
- seg_reset
- seg_kcode
- seg_kdata
- seg_kdata
- seg_tty

On le repère à ce que ils font partie des adresses hautes (bit de poids fort à 1).

** Question D1

Le programme utilisateur doit donner au noyau :
- la référence de l'appel système qu'il appelle
- les paramètres

La première information est facile à transmettre :
Les noms et les comportements des appels systèmes sont réputés connus de l'utilisateur (ils sont documentés) : il suffit de passer un nom, et le noyau a une liste statique des appels systèmes. Il cherche dans sa liste et trouve (ou non, auquel cas il rend une erreur).

La deuxième information est un peu plus délicate à transmettre : le noyau et le userspace n'ont pas la même pile : le noyau, qui a tous les droits, peut aller chercher les arguments directement dans la pile utilisateur du processus qui a fait l'appel système (c'est ce que faisait unix v5).

Sinon, comme c'est le cas ici, on peut stocker les arguments dans des registres visibles du processeur. Cette technique suppose une quantité limitée d'arguments.

En général, c'est même une technique mixte qui est utilisée : les premiers arguments peuvent être mis dans des registres, et la suite peut-être mise ou bien dans la pile ou bien dans une zone précise de l'espace mémoire du processus appelant.

** Question D2

Le tableau _cause_vector contient les raisons d'entrée en mode noyau. Il est initialisé dans le fichier exc_handler.c.

Le tableau _syscall_vector contient les points d'entrée des handlers des appels systèmes. Il est initialisé dans le fichier sys_handler.c.

D'après le code assembleur de la fonction _sys_handler, les handlers des appels systèmes sont indexés par leurs 5 bits de poids faible (donc 32 handlers) :

#+BEGIN_SRC mips
	  andi        $26,$2,0x1F
#+END_SRC

** Question D3

Dans l'ordre :

L'utilisateur appelle la fonction utilisateur proctime().

La fonction proctime() appelle la fonction inlinée sys_call(), avec comme premier argument 0x01, soit l'index de la fonction *noyau* _proctime() dans le tableau _syscall_vector.

La fonction syscall() enregistre dans des registres du processeur les arguments de la fonction, et il appelle l'instruction MIPS "syscall".

On fait l'hypothèse que cette instruction permet de passer en mode noyau (donc de rendre accessible des instructions processeur et des adresses), et de jump à une adresse bien précise. Ce passage en mode noyau se fait au moyen d'une trappe, soit une interruption matérielle.

On fait l'hypothèse, appuyée sur le code, qu'on saute à l'adresse 0x80000000 (en fait 0x80000000 + 0x180), soit l'adresse de la fonction assembleur _giet. Cette fonction assembleur du noyau a pour but de regarder quelle est la cause de l'interruption matérielle. Il se trouve que la cause de l'interruption matérielle courante suppose l'appel à la fonction assembleur _sys_handler.

On saute donc vers la fonction _sys_handler.

La fonction _sys_handler consulte le tableau _syscall_vector, et voit donc que le handler à appeler est la fonction _proctime.

_sys_handler saute donc vers la fonction _proctime (et il prend la peine de désactiver les interruptions : le noyau est *non-préemptif*) :

#+BEGIN_SRC mips
	  jalr        $3
	  mtc0        $0,$12                 
#+END_SRC

(on est en MIPS 32 bits, avec 5 étages de pipeline et un delayed slot : l'instruction mtc0 est exécutée malgré le jump)

La fonction _proctime consiste en une ligne d'assembleur, qui va lire le contenu du registre $9 du coprocesseur 0, censé apparemment contenir le nombre de cycles de processeurs écoulés depuis le démarrage de la machine (on ne sait pas trop comment, le code ne permet pas de le dire).

Cette valeur est copiée dans une variable de la pile, appelée ret. Cette variable est retournée par la fonction.

On se retrouve à la ligne suivante :

#+BEGIN_SRC mips
	  lw          $26,16($29)
	  mtc0        $26,$12
#+END_SRC

La fin de la fonction restaure les pointeurs de pile et d'instructions.

On se retrouve en mode utilisateur, à la fin de la fonction sys_call().

Qui retourne la valeur qui a été opportunément placée dans la pile au bon endroit (dans la variable reg_no_and_output).

On se trouve à la fin de la fonction proctime().

** Question D4

Cet appel système dont on vient de détailler le déroulement a le coût en *instructions* suivant, calculé sur la base des fichiers app.bin.txt et sys.bin.txt, qui sont les codes objets désassemblés :

Dans la fonction proctime :

400094:	27bdffe0 	addiu	sp,sp,-32
400098:	afbf001c 	sw	ra,28(sp)
40009c:	afbe0018 	sw	s8,24(sp)
4000a0:	03a0f025 	move	s8,sp
4000a4:	afa00010 	sw	zero,16(sp)
4000a8:	00003825 	move	a3,zero
4000ac:	00003025 	move	a2,zero
4000b0:	00002825 	move	a1,zero
4000b4:	24040001 	li	a0,1
4000b8:	0c100000 	jal	400000 <sys_call>
4000bc:	00000000 	nop

(soient 11 instructions)

Dans la fonction sys_call :

400000:	27bdfff8 	addiu	sp,sp,-8
400004:	afbf0004 	sw	ra,4(sp)
400008:	afbe0000 	sw	s8,0(sp)
40000c:	03a0f025 	move	s8,sp
400010:	afc40008 	sw	a0,8(s8)
400014:	afc5000c 	sw	a1,12(s8)
400018:	afc60010 	sw	a2,16(s8)
40001c:	afc70014 	sw	a3,20(s8)
400020:	8fc20008 	lw	v0,8(s8)
400024:	8fc4000c 	lw	a0,12(s8)
400028:	8fc50010 	lw	a1,16(s8)
40002c:	8fc60014 	lw	a2,20(s8)
400030:	8fc70018 	lw	a3,24(s8)
400034:	0000000c 	syscall

(soient 14 instructions)

Dans la fonction _giet :

80000180:	401b6800 	mfc0	k1,c0_cause
80000184:	3c1a8200 	lui	k0,0x8200
80000188:	275a00d0 	addiu	k0,k0,208
8000018c:	337b003c 	andi	k1,k1,0x3c
80000190:	035bd021 	addu	k0,k0,k1
80000194:	8f5a0000 	lw	k0,0(k0)
80000198:	03400008 	jr	k0
8000019c:	00000000 	nop

(soient 8 instructions)

Dans la fonction _sys_handler :

800001a0:	27bdffe8 	addiu	sp,sp,-24
800001a4:	401a6000 	mfc0	k0,c0_status
800001a8:	afba0010 	sw	k0,16(sp)
800001ac:	401b7000 	mfc0	k1,c0_epc
800001b0:	277b0004 	addiu	k1,k1,4
800001b4:	afbb0014 	sw	k1,20(sp)
800001b8:	305a001f 	andi	k0,v0,0x1f
800001bc:	001ad080 	sll	k0,k0,0x2
800001c0:	3c1b8200 	lui	k1,0x8200
800001c4:	277b031c 	addiu	k1,k1,796
800001c8:	037ad821 	addu	k1,k1,k0
800001cc:	8f630000 	lw	v1,0(k1)
800001d0:	241bffed 	li	k1,-19
800001d4:	401a6000 	mfc0	k0,c0_status
800001d8:	035bd024 	and	k0,k0,k1
800001dc:	0060f809 	jalr	v1
800001e0:	409a6000 	mtc0	k0,c0_status

(soient 17 instructions)

Dans la fonction _proctime :

80000520:	27bdfff0 	addiu	sp,sp,-16
80000524:	afbe000c 	sw	s8,12(sp)
80000528:	03a0f025 	move	s8,sp
8000052c:	40024800 	mfc0	v0,c0_count
80000530:	afc20000 	sw	v0,0(s8)
80000534:	8fc20000 	lw	v0,0(s8)
80000538:	03c0e825 	move	sp,s8
8000053c:	8fbe000c 	lw	s8,12(sp)
80000540:	27bd0010 	addiu	sp,sp,16
80000544:	03e00008 	jr	ra
80000548:	00000000 	nop

(soient 11 instructions)

De retour dans la fonction _sys_handler :

800001e4:	40806000 	mtc0	zero,c0_status
800001e8:	8fba0010 	lw	k0,16(sp)
800001ec:	409a6000 	mtc0	k0,c0_status
800001f0:	8fba0014 	lw	k0,20(sp)
800001f4:	409a7000 	mtc0	k0,c0_epc
800001f8:	27bd0018 	addiu	sp,sp,24
800001fc:	42000018 	eret

(soient 7 instructions)

De retour dans la fonction sys_call (on est donc sorti du mode noyau) :

400038:	03c0e825 	move	sp,s8
40003c:	8fbf0004 	lw	ra,4(sp)
400040:	8fbe0000 	lw	s8,0(sp)
400044:	27bd0008 	addiu	sp,sp,8
400048:	03e00008 	jr	ra
40004c:	00000000 	nop

(soient 6 instructions)

De retour dans la fonction proctime :

4000c0:	03c0e825 	move	sp,s8
4000c4:	8fbf001c 	lw	ra,28(sp)
4000c8:	8fbe0018 	lw	s8,24(sp)
4000cc:	27bd0020 	addiu	sp,sp,32
4000d0:	03e00008 	jr	ra
4000d4:	00000000 	nop

(soient 6 instructions)

Donc, depuis l'appel à la fonction proctime par le programme applicatif, à la sortie de cette même fonction, on a un coût en instructions :

*37 instructions* en mode utilisateur
*43 instructions* en mode système

Soient un grand total de *80 instructions*.

Si on suppose, en raison des delayed slots, cycles de gels, accès mémoire, etc..., un CPI de 2, on a donc *160 cycles* dépensés pour cet accès à proctime.

** Question E1

En général, le code de boot doit être exécuté en mode système parce que le boot consiste entre autres à charger le code du noyau en mémoire centrale, et en zone noyau de la mémoire centrale. Pour accéder en écriture à cette zone, on doit être en mode noyau.

Dans notre cas, quand bien même on suppose le code du noyau déjà chargé en mémoire au démarrage de la machine, on est quand même censé manipuler des registres, comme le registre SR, qui n'est accessible qu'en mode noyau.

** Question E2

L'adresse du point d'entrée du code applicatif doit se trouver au début du segment seg_data_base (soit exactement à l'adresse 0x01000000) :

#+BEGIN_SRC mips
	  la	         $26,seg_data_base
	  lw	         $26,0($26)          # get the user code entry point
	  mtc0	         $26,$14             # write it in EPC register
#+END_SRC

C'est bien cette adresse située à l'adresse 0x01000000 qui est chargée dans le compteur ordinal.

** Question E3

Si les adresses définies dans ces deux fichiers ne sont pas égales entre elles, le logiciel essaiera d'accéder à des adresses erronnées, puisque la base des segments pour le logiciel ne sera pas la même que la base des segments pour le matériel.

** Question E4

Le segment seg_reset contient seulement le code de la fonction assembleur reset.

Le segment seg_kcode contient le code de la fonction assembleur giet (le point d'entrée du noyau) et le code de toutes les fonctions du noyau définies dans les fichiers drivers.c, common.c, ctx_handler.c, irq_handler.c, sys_handler.c et exc_handler.c. Lors de la compilation, le code objet est préfixé d'une espèce de tag, .text, qui fait que l'éditeur de liens sait quelles fonctions mettre dans quel segment.

** Question E5

D'après le fichier sys.bin.txt, le segment seg_reset va des adresses [0xbfc00000 ; 0xbfc00023], soit 36 octets.

D'après le fichier sys.bin.txt, le segment seg_kcode effectivement occupé va des adresses [0x80000180 ; 0x8000227c] compris (on ne compte pas la section .MIPS.abiflags), soit :

8448 octets

** Question E6

#+BEGIN_SRC c
  #include "stdio.h"

  __attribute__((constructor)) void main()
  {
	  char c;
	  char s[] = "\n Hello World! \n";

	  while (1) {
		  tty_puts(s);
		  tty_getc(&c);
	  }
  }
#+END_SRC

** Question E7

Bien évidemment que la boucle non-déterministe (dans le sens où on ne saura pas quand on en sortira) est dans la fonction utilisateur tty_getc et non pas dans la fonction noyau _tty_read ! Aucun programmeur système sain d'esprit n'implémenterait une boucle non-déterministe dans du code noyau, surtout si le noyau est non-préemptif, multi-processus, en temps partagé (ce qui est le cas du GIET).

Les raisons pour ne pas faire ça sont légion, mais la plus évidente est la suivante : on a vu que les interruptions matérielles étaient masquées pendant l'exécution des fonctions noyau. Autrement dit, si la boucle avait été mise dans la fonction noyau, le processeur reste dans cette fonction noyau, oublieux de toutes les interruptions matérielles, même des interruptions horloge, *et rien ne peut plus l'en faire sortir* (sinon bien entendu le fait que l'utilisateur décide d'appuyer sur une touche de son clavier, ce qui peut très bien ne jamais arrivé). Ce processus qui exécute la fonction ne peut pas être tué, ne peut pas recevoir quelque signal que ce soit, et *ne peut pas être commuté*. Si il se trouve que le processeur est mono-coeur et mono-fil, alors la machine ne fait *rien d'autre* qu'attendre l'input de l'utilisateur.

En revanche, si on met la boucle dans le code utilisateur, le processus va faire plein d'appels système, mais il va régulièrement en sortir. Il peut donc recevoir des signaux, se faire tuer, se faire commuter si il prend trop de temps, etc... Autrement dit, le comportement qu'on attend d'un processus dans un noyau en multi-processus en temps partagé. Et surtout, les interruptions matérielles sont traitées par le système.

** Question E8

D'après le fichier app.bin.txt, le segment seg_code occupe les adresses [0x400000 ; 0x40134f] comprises, soient :

4944 octets

** Question E9

Makefile joint.

** Question F1

La première transaction sur le bus est une transaction rafale entre le maître, soit notre MIPS32 et la ROM, soit la target 0. C'est une requête en lecture des adresses 0xbfc00000, 0xbfc00004, 0xbfc00008, 0xbfc0000c qui correspondent bien aux adresses des quatre premières instructions de la fonction reset. La réponse à la première requête de la rafale est 0x27bd4000, soit l'instruction assembleur :

#+BEGIN_SRC mips
	  lui	    sp,0x200
#+END_SRC

D'après ce qu'on comprend de la trace, la première instruction du code du boot est exécuté au cycle 10 (pour une numérotation commençant à 0, soit le 11ème cycle, et pour une latence de la RAM de 0) :

#+BEGIN_QUOTE
,*******  cycle = 10 **************
bcu : fsm = IDLE
proc : <InsReq    valid mode MODE_KERNEL @ 0xbfc00000>
proc : <InsRsp    valid no error ins 0x3c1d0200>
proc : <DataReq invalid mode MODE_HYPER type DATA_READ @ 0 wdata 0 be 0>
proc : <DataRsp invalid no error rdata 0>
proc : ICACHE_IDLE  DCACHE_IDLE  PIBUS_IDLE
rom : IDLE
ram : IDLE
tty : IDLE   keyboard status[0] = 0   display status[0] = 0
  -- pibus signals -- 
req     = 0
gnt     = 0
sel_rom = 0
sel_ram = 0
sel_tty = 0
avalid  = 0
read    = 0x1
lock    = 0
address = 0xbfc0000c
ack     = 0x2
data    = 0x409a6000
#+END_QUOTE

C'est le premier cycle où InsRsp est valide, ce qui signifie qu'on a un cache hit sur l'adresse 0xbfc00000, et que donc le cache fournit la donnée 0x3c1d0200 au processeurs, qui la fait rentrer dans son pipeline.

La deuxième transaction sur le bus arrive au deuxième cache miss, soit au cycle 14 dans nos paramètres, parce qu'on a eu un cache miss sur l'adresse 0xbfc00010 :

#+BEGIN_QUOTE
,*******  cycle = 14 **************
bcu : fsm = IDLE
proc : <InsReq    valid mode MODE_KERNEL @ 0xbfc00010>
proc : <InsRsp  invalid no error ins 0x409a6000>
#+END_QUOTE

Cette deuxième transaction est donc une requête rafale en lecture à destination de la ROM, pour les adresses 0xbfc00010, 0xbfc00014, 0xbfc00018, 0xbfc0001c. La réponse à la première requête de la rafale est 0x3c1a0100, ce qui correspond à l'instruction assembleur :

#+BEGIN_SRC mips
	  lui	    k0,0x100
#+END_SRC

** Question F2

La première instruction à exécuter en mode utilisateur est demandée au cycle 50. C'est l'instruction située à l'adresse 0x004012dc, ce qui est bien la première instruction de main d'après app.bin.txt.

On a un cache miss, ce qui fait qu'on a une requête rafale en lecture, vers la ram, sur les adresses 0x004012d0, 0x004012d4, 0x004012d8, 0x004012dc (on demande trois adresses qui ne nous intéressent en fait pas, on ramène toute une ligne de cache).

L'instruction est effectivement exécutée au *cycle 60* : 

#+BEGIN_QUOTE
,*******  cycle = 60 **************
bcu : fsm = IDLE
proc : <InsReq    valid mode MODE_USER @ 0x4012dc>
proc : <InsRsp    valid no error ins 0x27bdffd0>
#+END_QUOTE

** Question F3

L'instruction de lecture du début de la chaîne de caractères "LF Hello World! LF" est l'instruction d'adresse 0x004012f0, celle-ci rentre dans le pipeline au cycle 91, le cache miss est détecté un cycle plus tard, au cycle 92, le bus est alloué au maître au cycle 93, et la demande rafale en lecture des adresses 0x01000070, 0x01000074, 0x01000078 (qui contient les 4 caractères 'LF', ' ', 'H' et 'e' qui nous intéressent) et 0x0100007c (qui contient les 4 caractères 'l', 'l', 'o', ' ') est faite au cycle *94*, on peut donc dater la première transaction à ce cycle-là.

** Question F4

On recherche le cycle auquel on a la première écriture d'un caractère vers le tty.

La question est ambigüe. Il peut s'agir soit du moment où l'instruction d'écriture du caractère entre dans le pipeline, soit du moment où elle est effectivement exécutée, soit du moment où la transaction d'écriture est lancée sur le bus.

La première instruction processeur d'écriture vers l'adresse 0x90000000 intervient au cycle 1160 (elle est rentrée dans le pipeline au cycle 1159) :

#+BEGIN_QUOTE
,*******  cycle = 1160 **************
bcu : fsm = IDLE
proc : <InsReq    valid mode MODE_KERNEL @ 0x800007f4>
proc : <InsRsp    valid no error ins 0x8fc20014>
proc : <DataReq   valid mode MODE_KERNEL type DATA_WRITE @ 0x90000000 wdata 0xa be 0xf>
proc : <DataRsp   valid no error rdata 0>
proc : ICACHE_IDLE  DCACHE_WRITE_REQ  PIBUS_IDLE
rom : IDLE
ram : IDLE
tty : IDLE   keyboard status[0] = 0   display status[0] = 0
  -- pibus signals -- 
req     = 0
gnt     = 0
sel_rom = 0
sel_ram = 0
sel_tty = 0
avalid  = 0
read    = 0x1
lock    = 0
address = 0x800007fc
ack     = 0x2
data    = 0xafc20014
#+END_QUOTE

La première transaction d'écriture sur le bus vers l'adresse 0x90000000 (soit la partie display du TTY) intervient au cycle 1163 :

#+BEGIN_QUOTE
,*******  cycle = 1163 **************
bcu : fsm = AD | selected target = 2
proc : <InsReq    valid mode MODE_KERNEL @ 0x800007fc>
proc : <InsRsp    valid no error ins 0xafc20014>
proc : <DataReq invalid mode MODE_KERNEL type DATA_READ @ 0x2003f6c wdata 0 be 0xf>
proc : <DataRsp invalid no error rdata 0>
proc : ICACHE_IDLE  DCACHE_IDLE  PIBUS_WRITE_AD
rom : IDLE
ram : IDLE
tty : IDLE   keyboard status[0] = 0   display status[0] = 0
  -- pibus signals -- 
req     = 0
gnt     = 0
sel_rom = 0
sel_ram = 0
sel_tty = 0x1
avalid  = 0x1
read    = 0
lock    = 0
address = 0x90000000
ack     = 0x2
data    = 0xafc20014
#+END_QUOTE



* TP 3 : 14/02/2020

Le but de ce TP est de commencer à modéliser le fonctionnement du cache L1.

** Application logicielle

*** Question C1

La fonction main est située au début du segment seg_code.

La première instruction est donc à l'adresse 0x00400000.

La première instruction de la boucle est à l'étiquette loop, donc quatre (en effet, la est une macro assembleur, qui est étendue à deux instructions après compilation) mots plus loin, soit en 0x00400010.

*** Question C2

Les trois tableaux A, B et C sont situés vers le début du segment seg_data.

Au début du segment seg_data, on a l'adresse de la fonction main sur 4 octets, puis un rembourrage de 124 octets.

On a donc l'adresse de base de A à 0x01000080.

A est un tableau d'entiers, chacun occupant un mot. On a donc 80 octets occupés par le tableau A, on a ensuite un rembourrage de 48 octets.

On a donc l'adresse de base de B à 0x01000100.

B est un tableau d'entiers, chacun occupant un mot. On a donc 80 octets occupés par le tableau B, on a ensuite un rembourrage de 48 octets.

On a donc l'adresse de base de C à 0x01000180

*** Question C3

On admet qu'on parle d'un MIPS32 avec 5 étages de pipeline, et donc un delayed slot.

Le sw doit être exécuté à chaque itération de la boucle, pour que la sémantique souhaitée soit respectée.

Il se trouve que ce sw est exécuté que à chaque itération de boucle : ce processeur a un delayed slot, ce qui fait qu'une instruction après chaque branchement est exécutée de manière inconditionnelle. On aurait pu mettre un nop, mais placer ici le sw permet de nous épargner un cycle gaspillé.

*** Question C4

On a pas de cycle de gel, donc on aura besoin de 7 cycles pour exécuter ces 7 instructions, si on suppose comme la consigne un système mémoire parfait.

** Fonctionnement du cache instruction

*** Question D1

Les caches sont à correspondance directe, donc NWAY égale 1.

On a 16 octets par ligne, on a donc besoin de log_2(16) bits pour identifier ces octets, soit 4.

Le champ BYTE fait donc 4 bits.

Pour minimiser la probabilité de miss de conflits, on s'arrange pour maximiser la distance minimale entre deux adresses devant aller dans le même emplacement.

Si on donne m le nombre d'emplacements du cache, cette distance minimale est maximale si on assigne à chaque adresse tronquée de l'offset (soit 28 bits dans notre cas) l'emplacement i, pour adresse % m = i (pour des emplacements étiquetés de 0 à m-1, naturellement).

Selon la valeur de m, le calcul de ce modulo devra faire intervenir un plus ou moins grand nombre des bits de poids faible de cette adresse tronquée. Dans notre cas m = 8, donc on aura 3 bits à regarder pour savoir où mettre ou chercher une adresse. Ces trois bits identifient exactement dans quel emplacement la donnée se trouve.

Donc SET a 3 bits.

TAG sera donc constitué des 25 bits de poids fort.

*** Question D2

Voilà l'état du cache d'instructions à la fin de la première itération (on donne les adresses complètes, pas les données, c'est beaucoup plus clair).

Reconstituons l'histoire de ce cache (en commençant du début de la fonction main).

Le processeur commence par demander l'adresse 0x00400000. Le cache fait miss, les mots d'adresse 0x00400000, 0x00400004, 0x00400008 et 0x0040000x sont chargés dans le cache (soient les mots qui correspondent aux instructions juste avant la boucle).

L'adresse de base de main est 0x00400000, et 0x00400000 tronqué des 4 bits de poids faible, soit 0x0040000 % 8 = 0, ce qui fait que les 4 premiers mots de main vont dans le premier set.

On aura donc SET = 0 = 0b000.

En entrant dans le boucle, le processeur demande l'adresse 0x00400010. Le cache fait miss, les mots d'adresse 0x00400010, 0x00400014, 0x00400018 et 0x0040001c sont chargés dans le cache (soient les 4 premières instructions de la boucle).

L'adresse de base de loop est 0x00400010, et 0x00040001 % 8 = 1, ce qui fait que les 4 premiers mots de loop vont dans le deuxième set.

On aura donc SET = 0 = 0b000.

En arrivant à l'instruction d'adresse 0x00400020 (add t4,t2,t3), le cache fait miss, les mots d'adresse 0x00400020, 0x00400024, 0x00400028 et 0x0040002c sont chargés dans le cache (soient les 3 dernières instructions de la boucle, et la première de print).

On n'aura plus de cache miss avant la fin de la boucle, donc voilà l'état du cache (on s'est permis de rajouter quelques colonnes pour expliciter)

| TAG + SET (sur 28 bits) | TAG (sur 25 bits) | SET (sur 3 bits) | V |      WORD3 |      WORD2 |      WORD1 |      WORD0 |
|-------------------------+-------------------+------------------+---+------------+------------+------------+------------|
|               0x0040000 |         0x0008000 |              0x0 | 1 | 0x0040000c | 0x00400008 | 0x00400004 | 0x00400000 |
|               0x0040010 |         0x0008000 |              0x1 | 1 | 0x0040001c | 0x00400018 | 0x00400014 | 0x00400010 |
|               0x0040020 |         0x0008000 |              0x2 | 1 | 0x0040002c | 0x00400028 | 0x00400024 | 0x00400020 |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |


*** Question D3

À la fin de la 20ème itération, le cache est dans le même état, on boucle sur les mêmes instructions qui sont déjà dans le cache :

| TAG + SET (sur 28 bits) | TAG (sur 25 bits) | SET (sur 3 bits) | V |      WORD3 |      WORD2 |      WORD1 |      WORD0 |
|-------------------------+-------------------+------------------+---+------------+------------+------------+------------|
|               0x0040000 |         0x0008000 |              0x0 | 1 | 0x0040000c | 0x00400008 | 0x00400004 | 0x00400000 |
|               0x0040010 |         0x0008000 |              0x1 | 1 | 0x0040001c | 0x00400018 | 0x00400014 | 0x00400010 |
|               0x0040020 |         0x0008000 |              0x2 | 1 | 0x0040002c | 0x00400028 | 0x00400024 | 0x00400020 |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |


On ne comprend pas très bien de la consigne sur quelle section de code précise on doit calculer le taux de miss.

On va donc en calculer plusieurs.

*Si on ne considère que la boucle du main*, on ne fait que deux miss sur les 20 itérations, soient 2 miss sur 20 x 7 = 140 instructions, ce qui fait un taux de miss de 1.42 % (1/70).

*Si on considère le main en entier*, sans les instructions de l'appel de fonction tty_puts, on a 1 miss dans main, 2 dans loop, puis 2 dans print et 0 dans suicide.

Soient 5 miss pour 4 + 7 x 20 + 6 + 2 = 152 instructions, ce qui fait un taux de miss de 3,29 % (5/152).

*** Question D4

L'état de cache MISS_SELECT est nécessaire quand il est besoin de désigner un emplacement à vider de son contenu pour accueillir la nouvelle donnée qu'on veut faire rentrer dans le cache. Quand on n'a de toute façon qu'un seul emplacement possible, la désignation est vite faite. On a donc besoin de cet état uniquement quand le degré d'associativité est strictement supérieur à 1.

On en a pas besoin dans notre cas, on est en direct mapping.

*** Question D5

**** Noeud IDLE

A = IREQ.IUNC.IMISS
B = IREQ.IMISS.C(IUNC)
C = C(IREQ) + IREQ.C(IMISS)

On a C.A = 0 et C.B = 0

A.B = 0 aussi.

L'orthogonalité est vérifiée.

A + B = IREQ.IMISS

A + B + C = IREQ.IMISS + C(IREQ) + IREQ.C(IMISS) = C(IREQ) + IREQ.(IMISS + C(IMISS)) = C(IREQ) + IREQ = 1

La complétude est vérifiée de même.

**** Noeud MISS_WAIT

F = VALID.C(ERROR)
G = VALID.ERROR
H = C(VALID)

H est orthogonal avec F et G, on l'élimine.

F et G sont orthogonaux.

On a l'orthogonalité.

F + G = VALID.C(ERROR) + VALID.ERROR = VALID
H + F + G = C(VALID) + VALID = 1

La complétude est vérifiée de même.

**** Noeud UNC_WAIT

J = C(VALID)
K = VALID.ERROR
L = VALID.C(ERROR)

J est orthogonal avec K et L, on l'élimine.

K et L sont orthogonaux.

On a l'orthogonalité.

K + L = VALID.ERROR + VALID.C(ERROR) = VALID
K + L + J = VALID + C(VALID) = 1

La complétude est vérifiée de même.

**** Noeuds UNC_GO, MISS_SELECT, MISS_UPDT et ERROR

M = 1
O = 1
I = 1
F = 1

On sort de ces quatre états de manière inconditionnée vers un unique noeud dans chaque cas. On a l'orthogonalité et la complétude par construction.

*** Question D6

Cet automate est forcé dans l'état IDLE lors de l'activation du signal RESETN. Ce dernier a pour autre effet d'invalider tout le cache d'instructions.

** Fonctionnement du cache de données

*** Question E1

A[0] est à l'adresse 0x01000080, comme on l'a vu plus haut. BYTE correspond aux 4 bits de poids faible, donc 0. SET correspond aux trois bits suivants, sera donc à 0 aussi. TAG sera les 25 bits de poids fort, soit 0x0020001.

B[0] est à l'adresse 0x01000100, comme on l'a vu plus haut. BYTE correspond aux 4 bits de poids faible, donc 0. SET correspond aux trois bits suivants, sera donc à 0 aussi. TAG sera les 25 bits de poids fort, soit 0x0020002.

Rappelons le déroulement du programme pour trouver les miss de données :

Lors du premier lw, on a un miss sur l'adresse 0x01000080, on charge donc dans le premier emplacement du cache de données les mots d'adresse l'adresse 0x01000080, 0x01000084, 0x01000088 et 0x0100008c.

Lors du deuxième lw, on a un miss sur l'adresse 0x01000100, on charge donc dans le premier emplacement du cache de données les mots d'adresse l'adresse 0x01000180, 0x01000184, 0x01000188 et 0x0100018c. Ce faisant, on évince les 4 mots qui s'y trouvaient déjà.

À la fin de la première itération de la boucle, le cache de données ressemble à ça.

| TAG + SET (sur 28 bits) | TAG (sur 25 bits) | SET (sur 3 bits) | V |      WORD3 |      WORD2 |      WORD1 |      WORD0 |
|-------------------------+-------------------+------------------+---+------------+------------+------------+------------|
|               0x0100010 |         0x0020001 |              0x0 | 1 | 0x0100010c | 0x01000108 | 0x01000104 | 0x01000100 |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |

*** Question E2

Pour la première itération, on a un miss compulsif pour A[0], puis un miss de conflit pour B[0]

Pour les trois itérations suivantes, on a deux miss de conflits : les éléments de A et ceux de B se chassent mutuellement.

Pour la cinquième itération, on est à nouveau dans le même cas que dans la première question, sauf qu'on va se battre pour le deuxième emplacement.

Et ainsi de suite.

On a donc exactement deux miss par itération, soit en fait un muss par lw, ce qui fait un taux de miss en lecture de 100% (40/40).

Voilà l'état du cache de données à la fin de la 20ème itération. Seuls les 5 premiers emplacements sont utilisés, et sont remplis des éléments de B, ceux-ci ayant chassé les éléments de A.

| TAG + SET (sur 28 bits) | TAG (sur 25 bits) | SET (sur 3 bits) | V |      WORD3 |      WORD2 |      WORD1 |      WORD0 |
|-------------------------+-------------------+------------------+---+------------+------------+------------+------------|
|               0x0100010 |         0x0020001 |              0x0 | 1 | 0x0100010c | 0x01000108 | 0x01000104 | 0x01000100 |
|               0x0100011 |         0x0020001 |              0x1 | 0 | 0x0100011c | 0x01000118 | 0x01000114 | 0x01000110 |
|               0x0100012 |         0x0020001 |              0x2 | 0 | 0x0100012c | 0x01000128 | 0x01000124 | 0x01000120 |
|               0x0100013 |         0x0020001 |              0x3 | 0 | 0x0100013c | 0x01000138 | 0x01000134 | 0x01000130 |
|               0x0100014 |         0x0020001 |              0x4 | 0 | 0x0100014c | 0x01000148 | 0x01000144 | 0x01000140 |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |
|                         |                   |                  | 0 |            |            |            |            |


*** Question E3

**** Noeud IDLE

A = DREQ.C(WRITE).DMISS.DUNC
B = DREQ.C(WRITE).DMISS.C(DUNC)

C = C(DREQ) + DREQ.C(DMISS).C(WRITE)

D = DREQ.WRITE.C(DMISS)
E = DREQ.WRITE.DMISS

A et B sont orthogonaux, et A + B = DREQ.C(WRITE).DMISS

D et E sont orthogonaux, et D + E = DREQ.WRITE

A + B et D + E sont orthogonaux.

C est orthogonal avec A + B (premier terme à cause de DREQ, et deuxième à cause de DMISS).
C est orthogonal avec D + E (premier terme à cause de DREQ, et deuxième à cause de WRITE).

On a l'orthogonalité par développement.

C + D + E = C(DREQ) + DREQ.C(DMISS).C(WRITE) + DREQ.WRITE = C(DREQ) + DREQ.(C(DMISS).C(WRITE) + WRITE)

A + B + C + D + E = DREQ.C(WRITE).DMISS + C(DREQ) + DREQ.(C(DMISS).C(WRITE) + WRITE)
A + B + C + D + E = C(DREQ) + DREQ.(C(DMISS).C(WRITE) + WRITE + C(WRITE).DMISS)
A + B + C + D + E = C(DREQ) + DREQ.(WRITE + C(WRITE).(C(DMISS) + DMISS))
A + B + C + D + E = C(DREQ) + DREQ.(WRITE + C(WRITE).(1))
A + B + C + D + E = C(DREQ) + DREQ.(1)
A + B + C + D + E = 1

On a la complétude de même.

**** Noeud MISS_WAIT

F = VALID.C(ERROR)
G = VALID.ERROR
H = C(VALID)

On a H orthogonal avec F et G, et F et G orthogonaux entre eux.

On a donc bien l'orthogonalité.

F + G = VALID.C(ERROR) + VALID.ERROR = VALID
F + G + H = VALID + C(VALID) = 1

On a la complétude de même.

**** Noeud UNC_WAIT

J = C(VALID)
K = VALID.ERROR
L = VALID.C(ERROR)

On a J orthogonal avec K et L, et K et L orthogonaux entre eux.

On a donc bien l'orthogonalité.

K + L = VALID.C(ERROR) + VALID.ERROR = VALID
K + L + J = VALID + C(VALID) = 1

On a la complétude de même.

**** Noeuds WRITE_UPDT, UNC_GO, ERROR, MISS_SELECT, MISS_UPDT

On quitte ces états de manière inconditionnée, à chaque fois vers un autre état unique.

On a donc :

M = 1
P = 1
I = 1
N = 1

Sur ces quatre noeuds, on a l'orthogonalité et la complétude de manière évidente.

*** Question E4

Comme le dit la consigne, les états successeurs de l'état WRITE_REQ sont les mêmes que les états successeurs de l'état IDLE.

La différence est l'évaluation du signal WOK. On ne sort de cet état que si le tampon d'écritures postées n'est pas plein.

Donc la boucle de WRITE_REQ vers WRITE_REQ (nommons la E') a comme condition C(WOK) + WOK.E (on reste soit si le tampon d'écriture postée est plein, soit pour les mêmes raisons qu'on va de IDLE vers WRITE_REQ, en vérifiant que le tampon d'écritures postées n'est pas plein).

Toutes les autres transitions de WRITE_REQ, soient A' (vers UNC_WAIT), B' (vers MISS_SELECT), C' (vers IDLE) et D' (vers WRITE_UPDT) pourront s'écrire :

A' = WOK.A
B' = WOK.B
C' = WOK.C
D' = WOK.D

En développant, on garde bien la complétude et l'orthogonalité.

** Accès au PIBUS

*** Question F1

Ici, on peut répondre différemment selon les hypothèses qu'on fait sur le tampon d'écritures postées.

Quand on fait une lecture de données, prend-on la peine de vérifier le tampon d'écritures postéées, pour voir si par hasard la dernière version de la donnée ne s'y trouverait pas ?

Si non, alors ne pas rendre les écritures prioritaires sur le bus revient à immédiatement violer la consistance mémoire. On est obligé de rendre les écritures absolument prioritaires, simplement pour garantir la consistance.

Si en revanche on suppose que cette vérification est faite, on peut trouver aussi des raisons certes un peu plus faibles :

Le tampon d'écritures postées est de petite taille par rapport au cache (conséquent nécessaire de la vérification du tampon d'écritures postées !), il se remplit donc plus vite. Pour cette raison, on pourrait avoir envie de le rendre prioritaire.

Les programmes ont aussi tendance à faire les lw avant les sw, ce qui fait qu'un programme a déjà du matériau en réserve pour travailler quand le tampon d'écritures se met à monopoliser le bus. On espère que le prochain miss arrivera le plus tard possible après le début de cette monopolisation. D'une certaine manière, les effets vicieux de cette monopolisation sont un peu mitigés par l'ordre "naturel" des programmes.

L'inconvénient est évident, ce sont les famines potentielles pour les caches d'instructions et de données qui veulent accéder au bus. Ces famines sont ceci étant dit limitées d'elles-même. Si on ne peut plus chercher des instructions, le tampon d'écriture postées va se vider très vite, puisque rien ne peut plus le venir remplir.

*** Question F2

Comme pour tous les maîtres, d'après le schéma général du PIBUS, ICACHE_ISM et DCACHE_ISM demanderont le bus à l'aide du signal REQ.

Comme pour tous les maîtres, le maître répondra dans le même cycle avec le signal GNT.

Ici, on considère le PIBUS_FSM comme une espèce de serveur. Mais la question fait ici une supposition erronée, ce n'est pas le "serveur" (soit le PIBUS) qui signale au "client" que les données sont disponibles, c'est la cible directement (c'est la limite de cette analogie : le "serveur" est en fait plus un routeur !) ! La cible signale au maître que les données sont disponibles avec le signal ACK.

*** Question F3

Sur une requête d'écriture transmise sur le bus par le tampon d'écritures postées, il y a effectivement une réponse ! Celle-ci est transmise par la cible, via le signal ACK. Cette réponse est vitale, elle sert à savoir si la requête était valide. Si elle ne l'était pas, il faut bien le dire au processeur pour qu'il puisse déclencher l'interruption qui aboutira très probablement à la mort du processus fautif.

Pour répondre à la question, le PIBUS_FSM ne signale pas qu'une requête est terminée, parce que ce n'est pas son rôle ! C'est à la cible de le faire.

*** Question F4

**** Noeud IDLE

X = GNT.(ROK + SC)
Y = GNT.C(ROK).C(SC).(IUNC + IMISS + DUNC + DMISS)
Z = C(GNT)

X et Y sont orthogonaux.
Z est orthogonal avec X et Y.

On a donc l'orthogonalité.

X + Y = GNT.(ROK + SC) + GNT.C(ROK).C(SC).(IUNC + IMISS + DUNC + DMISS)
X + Y = GNT.(ROK + SC + C(ROK).C(SC).(IUNC + IMISS + DUNC + DMISS))

X + Y = GNT.(ROK.(IUNC + IMISS + DUNC + DMISS) + ROK.(C(IUNC).C(IMISS).C(DUNC).C(DMISS)) + SC.(IUNC + IMISS + DUNC + DMISS) + SC.(C(IUNC).C(IMISS).C(DUNC).C(DMISS)) + C(ROK).C(SC).(IUNC + IMISS + DUNC + DMISS))

X + Y = GNT.((IUNC + IMISS + DUNC + DMISS).(ROK + SC + C(ROK).C(SC)) + ROK.(C(IUNC).C(IMISS).C(DUNC).C(DMISS)) + SC.(C(IUNC).C(IMISS).C(DUNC).C(DMISS)))

X + Y = GNT.((IUNC + IMISS + DUNC + DMISS).(1) + ROK.(C(IUNC).C(IMISS).C(DUNC).C(DMISS)) + SC.(C(IUNC).C(IMISS).C(DUNC).C(DMISS)))

X + Y = GNT.((IUNC + IMISS + DUNC + DMISS) + (ROK + SC).(C(IUNC).C(IMISS).C(DUNC).C(DMISS)))

IUNC et ROK peuvent être considérés comme des événements disjoints : quand ROK est positionné, on ne tient aucun compte de IUNC, c'est comme si ce signal n'existait pas (c'est le sens de la priorité fixe).

Donc si ROK et IUNC sont des événements disjoints, on a ROK.C(IUNC) = ROK.

De même avec SC...

On peut donc simplifier X + Y comme ceci :

X + Y = GNT.(IUNC + IMISS + DUNC + DMISS + ROK + SC)

Les événements IUNC, IMISS, DUNC, DMISS, ROK, SC sont les seuls possibles dans le modèle qu'on s'est donné. Ils constituent l'univers, on a donc 

IUNC + IMISS + DUNC + DMISS + ROK + SC = 1

Soit X + Y = GNT.

Donc X + Y + Z = C(GNT) + GNT = 1.

On a bien la complétude.

*** Question F5

Voilà comment le cache se comporte, si on suppose que le instruction fetch du MIPS termine sans instruction chargée à la fin de l'étage I au cycle n.

Cycle n : Le processeur demande une instruction, il ne l'a pas à la fin de son Instruction Fetch, le cache est informé à la fin de ce cycle, le cache est en position MISS_SELECT et l'emplacement à vider est choisi.
Cycle n + 1 : Le cache se met en position MISS_WAIT. Le cache demande le bus, il l'obtient à la fin du cycle si tout se passe bien.
Cycle n + 2 : Le cache envoie la première adresse de la rafale.
Cycle n + 3 : Le cache reçoit la première donnée, et envoie la deuxième adresse.
Cycle n + 4 : Le cache reçoit la deuxième donnée, et envoie la troisième adresse.
Cycle n + 5 : Le cache reçoit la troisième donnée, et envoie la quatrième adresse.
Cycle n + 6 : Le cache reçoit la quatrième donnée.
Cycle n + 7 : ?
Cycle n + 8 : Le cache met à jour l'emplacement qu'il avait choisi au cycle n + 1.
Cycle n + 9 : Le cache envoie l'instruction au processeur, qui la reçoit à la fin du cycle.
Cycle n + 10 : Le processeur fait rentrer l'instruction dans son pipeline.

Le processus est sensiblement le même pour le miss de données.

Le processeur est gelé des cycles n + 1 à n + 9 compris, soient 9 cycles de gel.

Le cycle n + 7 correspond à un cycle qu'on a constaté dans la trace, mais pour lequel on n'a pas vraiment d'explication pour le moment.

On trouvera le chronogramme en annexe.

*** Question F6

On a donc 9 cycles de gel par miss d'instruction ou de données.

Sur 20 itérations, on a 2 miss d'instructions, soient 18 cycles de gel liés aux miss d'instructions.

Sur 20 itérations, on a 40 miss de données, soient 40 x 9 = 360 cycles de gel liés aux miss de données.

Soient 378 cycles de gel liés aux miss toutes catégories confondues.

On a 140 instructions, un cycle par instruction.

Ce qui fait un CPI théorique de 518 / 140 = 3.7.

** Expérimentation par simulation

*** Question G1

Si on numérote les cycles à compter du cycle 0 (comme la trace), la première instruction rentre dans le pipeline au cycle 10.

Cette instruction est la première instruction de reset, la partie du code du GIET devant être exécutée à la mise sous tension de la machine.

Si on excepte le premier miss, le coût d'un miss sur le cache d'instructions est de 9 cycles.

*** Question G2

D'après la trace, la première instruction du main, d'adresse 0x00400000, rentre dans le pipeline au cycle 57.

*** Question G3

Un miss sur le cache de données occasionne 9 cycles de gel pendant la première itération, puis 13 sur la prochaine et la suivante.

Le processeur fait rentrer la dernière instruction de la première itération dans son pipeline au cycle 108, sachant qu'il avait fait rentrer la première au cycle 71, ce qui donne 37 cycles.

*** Question G4

La seconde itération et la suivante durent 31 cycles, soit moins que la première. Cette état de chose s'explique par les miss compulsifs sur les instructions lors de la première instruction.

Ceci étant dit, le coût du miss de données est plus élevé : il occasionne 9 cycles de gel à la première itération, et 13 aux deuxième et troisième.

Ceci s'explique par l'entrée en jeu du tampon d'écritures postées, qui commence à utiliser de manière prioritaire le bus à partir de la toute fin de la première itération.

*** Question G5

On a en tout 40 lw dans les 20 itérations, on fait miss sur chacune d'entre elle, soit un taux de miss de 100 %.

La dernière instruction de la dernière itération de main entre dans le pipeline au cycle 696, et la première instruction de la première itération entre dans le pipeline au cycle 71.

On a donc 625 cycles pour toute la boucle, soit un CPI constaté de 4.46 (la différence avec le CPI théorique s'explique par la non prise en compte du tampon d'écriture postée).

** Optimisation

Dans la manière dont est codée cette application, on s'est arrangé pour maximiser le nombre de miss sur le cache de données en maximisant les miss de conflits. Pour ce faire, les adresses des données nécessaires au même moment ont été exprès alignées sur des blocs de 128 octets, ce qui représente littéralement le pire agencement possible (taux de miss de 100 %).

Une manière simple de grandement optimiser ce programme et de briser cet alignement en supprimant le rembourrage de 48 octets à la fin du premier tableau.

Comme ceci :

#+BEGIN_SRC asm
  #################################################################################
  #	File : main.s
  #	Author : Aymeric Agon-Rambosson
  #       Date : 16/02/2020
  #################################################################################
  #       This is a very simple application directly written in MIPS32
  #	assembly language, in order to precisely control the memory mapping.
  #	The sections names are specific to control the linker.
  #################################################################################

	  .section 	.mydata

	  .word	main
	  .space  124

  A :	.word	  1,  2,  3,  4,  5,  6,  7,  8,  9, 10
	  .word	 11, 12, 13, 14, 15, 16, 17, 18, 19, 20

  B :	.word	101,102,103,104,105,106,107,108,109,110
	  .word	111,112,113,114,115,116,117,118,119,120
	  .space 96

  C :	.word	  0,  0,  0,  0,  0,  0,  0,  0,  0,  0
	  .word	  0,  0,  0,  0,  0,  0,  0,  0,  0,  0

	  .section 	.mycode

	  .set noreorder
  main :	
	  la   $8, 	A		# $8 <= &A[0]
	  li   $7, 	20	        # $7 <= 20
	  li   $6, 	0		# $7 <= 0
		
  loop :	
	  lw   $10, 	0($8)		# $10 <= A[i]
	  lw   $11, 	80($8)		# $11 <= B[i]
	  addi $6, 	$6, 	1	# i <= i+1
	  addi $8, 	$8, 	4	# $8 <= &A[i+1]
	  add  $12, 	$10, 	$11	# $12 <= A[i]+B[i]
	  bne  $6, 	$7, 	loop	# fin de boucle ?
	  sw   $12, 	252($8)	        # C[i] <= $12
  print:
	  la   $4, message
	  addi $29,       $29,     -4
	  jal  tty_puts
	  nop
	  addi $29,       $29,     +4
  suicide:	
	  jal  exit
	  nop
  message:
	  .asciiz   "\n!!! vector sum completed !!!\n"

#+END_SRC

Avec cette nouvelle organisation de la mémoire, on aura seulement 10 miss compulsifs sur le cache de données sur la totalité de la boucle, et aucun miss de conflit : on n'évince une ligne qu'après avoir fini d'en avoir besoin.

On a 30 cache miss en moins, soient un peu plus de 9 x 30 = 270 cycles de gel en moins (tous les cache miss ne coûtent pas 9 cycles, comme on l'a vu).

Le nombre de cycles pour l'exécution totale du programme sera donc un peu supérieur à 518 - 270 = 248 cycles, soient environ 12.4 cycles par itération, soit un CPI théorique de 1.77.


Le plus simple est encore de simuler.

Après réassemblage, on a la dernière instruction de la dernière itération de la boucle qui rentre dans le pipeline au cycle 336.  

La première instruction de la première itération de la boucle était rentrée dans le pipeline au cycle 71.

Ce qui nous fait 336 - 71 = 265 cycles, ce qui est assez proche de ce qu'on avait prévu.

On a 265 cycles pour 140 instructions, soit un CPI constaté de 1.9, ce qui est bien mieux (la différence s'explique encore une fois par le tampon d'écriture postée, mais elle est plus faible que dans l'exécution non-optimisée parce qu'on a volontairement sous-estimé l'effet de nos optimisations en prenant un coût en cycles de gel moyen de 9 alors qu'il est en fait plus proche de 13).


* TP 4 : 21/02/2020

Cette semaine, on se propose de faire varier les caractéristiques des caches, pour en déduire par analyse numérique les caractéristiques optimales.

** Système mémoire presque parfait

*** Question C1

On se propose, pour mesurer le temps d'exécution, de regarder le contenu du pseudo-registre c_total_cycles qui est gentiment affiché dans le pseudo-tty à la fin du calcul.

Avec 256 sets, 16 mots par ligne, un degré d'associativité de 4, et un tampon d'écritures postées d'une profondeur de 8 mots, le programme se termine à la fin du cycle 74502.

*** Question C2

Maintenant qu'on connaît le nombre de cycles nécessaires pour terminer le calcul, on peut demander 75000 cycles, et une période d'échantillonnage des statistiques de 1000, de manière à regarder dans un premier temps les taux de miss cumulatifs et le CPI sur la totalité de la période.

Sur le calcul considéré dans sa totalité, on a un taux de miss sur le cache d'instructions de 0,06 %, un taux de miss sur le cache de données de 0,1 %, et un CPI de 1,32.

Si on regarde l'évolution des taux de miss cumulatifs sur la totalité du calcul (des cycles 1 à 75000), on voit qu'ils sont décroissants pour les instructions et les données. La décroissance est très rapide au début, puis ralentit à partir du 10000ème cycle. Le CPI suit la même tendance.

Si on regarde en particulier les 1000 premiers cycles, on a une décroissance en tendance de même, avec une légère remontée autour des cycles 200 et 400 pour le taux de miss de données (et donc pour le CPI). Les trois grandeurs se stabilisent à partir des cycles 700-800.

La décroissance rapide des taux de miss est dû au miss compulsifs qui sont par définition concentrés au début de l'exécution des programmes : dès lors que les instructions sont chargées dans le cache, on fait très peu de miss, surtout si le cache est presque parfait : peu de miss de conflit, et peu de miss de capacité.

La remontée du taux de miss sur les caches de données est probablement dûe à un changement de contexte (passage du système à l'applicatif, par exemple).

On trouvera en annexe deux graphiques.

*** Question C3

Voilà la section du code qui décrit la définition des statistiques, dans le fichier pibus_mips32_xcache.cpp.

#+BEGIN_SRC c++
  void PibusMips32Xcache::printStatistics()
  {
	  std::cout << "*** " << name() << " at cycle " << std::dec <<
		  c_total_cycles << std::endl;
	  std::cout << "- INSTRUCTIONS       = " << c_total_inst << std::endl ;
	  std::cout << "- CPI                = " <<
		  (float)c_total_cycles/c_total_inst << std::endl ;
	  std::cout << "- CACHED READ RATE   = " <<
		  (float)(c_dread_count-c_dunc_count)/c_total_inst << std::endl;
	  std::cout << "- UNCACHED READ RATE = " <<
		  (float)c_dunc_count/c_total_inst << std::endl ;
	  std::cout << "- WRITE RATE         = " <<
		  (float)c_write_count/c_total_inst << std::endl;
	  std::cout << "- IMISS RATE         = " <<
		  (float)c_imiss_count/c_total_inst << std::endl;
	  std::cout << "- DMISS RATE         = " <<
		  (float)c_dmiss_count/(c_dread_count-c_dunc_count) << std::endl;
	  std::cout << "- IMISS COST         = " <<
		  (float)c_imiss_frz/c_imiss_count << std::endl;
	  std::cout << "- DMISS COST         = " <<
		  (float)c_dmiss_frz/c_dmiss_count << std::endl;
	  std::cout << "- UNC COST           = " <<
		  (float)c_dunc_frz/c_dunc_count << std::endl;
	  std::cout << "- WRITE COST         = " <<
		  (float)c_write_frz/c_write_count << std::endl;
  }
#+END_SRC

À chaque cycle, est gardé dans un pseudo-registre (c_total_instructions) le nombre total d'instructions exécutées depuis le démarrage de la machine, simplement incrémenté à chaque fois que :
- une requête d'instructions est valide
- la réponse est valide
- l'adresse demandée n'est pas la même qu'à l'instruction précédente

Voyons plutôt :

#+BEGIN_SRC c++
  if (m_ireq.valid && m_irsp.valid && (m_ireq.addr != r_icache_save_addr.read()))
	  c_total_inst++;
#+END_SRC

Dans un autre pseudo-registre, c_total_cycles, on garde le nombre de cycles passés depuis le démarrage de la machine, simplement incrémenté à chaque cycle.

Dans un autre pseudo-registre, c_imiss_count, on garde le nombre de miss d'instructions depuis le démarrage de la machine. Ce compteur est incrémenté à chaque miss d'instructions.

Dans un autre pseudo-registre, c_imiss_frz, on garde le nombre de cycles passés à attendre en raison d'un miss d'instructions. Ce compteur est incrémenté à chaque cycle passé à attendre une inscription.

Dans un autre pseudo-registre, c_dmiss_count, on garde le nombre de miss de données depuis le démarrage de la machine. Ce compteur est incrémenté à chaque miss de données.

Dans un autre pseudo-registre, c_dread_count, on garde le nombre d'instructions qui sont des lectures. Ce compteur est incrémenté à chaque fois que l'opcode de l'instruction assembleur correspond à lw, lb, ou lh.

Dans un autre pseudo-registre, c_dunc_count, on garde le nombre d'instructions de lecture vers des adresses non cachables.

Avec tous ces registres, on a tout ce qu'il faut pour définir correctement toutes les statistiques qui nous intéressent :

Le CPI cumulatif est le quotient du nombre total de cycles par le nombre total d'instructions.
Le taux de miss d'instructions est le quotient du nombre total de miss d'instructions par le nombre total d'instructions.
Le coût d'un miss d'instructions est le quotient du nombre total de cycles de gel passés à attendre une instruction par le nombre total de cycles.
Le taux de miss de données est le quotient du nombre total de miss de données par le nombre d'instructions de lecture.
Le coût d'un miss de données est le quotient du nombre total de cycles de gel passés à attendre une donnée pour lecture par le nombre total d'instructions de lecture vers des adresses non cachables.

Les statistiques affichées par le programme simul.x correspondent bien à ces grandeurs, cf. le code source plus haut.

** Influence de la capacité du cache d'instructions

*** Question D1

Faisons le résumé des statistiques demandées :

| Nombre de sets |  Durée | Taux de miss | Coût du miss |  CPI |
|----------------+--------+--------------+--------------+------|
|            256 |  85956 | 1.48 %       |         15.3 | 1.54 |
|             64 | 106270 | 3.88 %       |         15.7 | 1.95 |
|             16 | 152943 | 10.01 %      |         15.6 | 2.97 |
|              4 | 166455 | 12.04 %      |         15.5 | 3.29 |
|              1 | 234079 | 23.50 %      |         15.2 | 5.11 |

Il est tout à fait logique que le taux de miss et le CPI se dégradent, conduisant à des temps d'exécution plus longs, avec la diminution du nombre de cases. Tout simplement parce qu'en diminuant le nombre de cases, et en laissant les autres paramètres inchangés, on diminue la taille du cache : les miss de conflits et de capacité seront beaucoup plus fréquents : les lignes se battront pour un plus petit nombre de cases, et le cache ne pourra tenir qu'un plus petit nombre d'instructions à la fois : les localités spatiale et temporelle seront moins bien exploitées.

Le coût du miss reste constant en la taille du cache, parce qu'il dépend d'autre chose : il dépend des caractéristiques des matériels qui passent avant lui sur le bus, en particulier de la profondeur du tampon d'écritures postées.

*** Question D2

Comme on vient de le mentionner, le coût du miss d'instructions dépend des caractéristiques des matériels qui passent avant lui sur le bus, au premier rang desquels le tampon d'écriture postées, et aussi de la fréquence à laquelle le programme fait accéder à ce tampon d'écritures postées.

Le tampon d'écritures postées a les mêmes caractéristiques que la semaine dernière (profondeur de 8), donc ce n'est pas la cause ici. En revanche, on n'exécute pas du tout le même programme que la semaine dernière, celui de cette semaine fait beaucoup plus d'entrées-sorties (des écritures dans le pseudo-terminal, en particulier). Le tampon d'écritures postées sera beaucoup plus souvent non-vide, donc va occuper le bus de manière prioritaire plus souvent, augmentant le coût des miss pour ceux qui passent après lui.

Le coût du miss peut être représenté par une variable aléatoire : il dépend de l'état de remplissage du tampon d'écritures postées au moment où le miss se produit. On ne peut pas donner une valeur a priori du coût du miss, celui-ci sera variable.

Le coût ici donné est une moyenne des coûts des miss constatés *dans ce programme bien précis*. Une moyenne de valeurs entières peut parfaitement être une valeur non entière.

** Influence de la largeur de la ligne de cache

| Nombre de sets | Taille du set |  Durée |
|----------------+---------------+--------|
|            256 |             1 | 193355 |
|            128 |             2 | 148381 |
|             64 |             4 | 130274 |
|             32 |             8 | 124855 |
|             16 |            16 | 129468 |
|              8 |            32 | 149237 |

La configuration la plus efficace, c'est 32 sets de 8 mots, soit 32 sets de 32 octets chacun.

Si on augmente la taille de la ligne, on espère faire diminuer le taux de miss, mais on augmente le coût d'un miss : on doit transmettre plus de choses sur le bus.
Si on diminue la taille de la ligne, on espère faire diminuer le coût d'un miss, mais on augmente le taux de miss.

Le coût effectif du miss en nombre de cycles étant le produit du taux et du coût par miss, il est logique, par raison mathématique (on parle d'une fonction quadratique), que la configuration optimale sera sur les valeurs médianes de l'un et de l'autre.

On trouvera le graphique qui montre les durées en cycle en fonction de la largeur en annexe.

** Influence de la capacité du cache de données

| Nombre de sets |  Durée | Taux miss données | Coût miss données |  CPI |
|----------------+--------+-------------------+-------------------+------|
|            256 |  74553 | 0.2 %             |              17.7 | 1.32 |
|             64 |  74638 | 0.2 %             |              17.8 | 1.32 |
|             16 |  94444 | 7.1 %             |              18.4 | 1.68 |
|              4 | 144880 | 22.3 %            |             16.77 | 2.56 |
|              1 | 218474 | 38.0 %            |              15.8 | 3.86 |

Encore une fois, des résultats très logiques : diminuer le nombre de cases de cache de données augmente mécaniquement le taux des miss de conflit et de capacité : les lignes se battent pour un moindre nombre de cases, les localités spatiales et temporelles des données sont moins bien exploitées.

** Influence de la profondeur du tampon d'écritures postées

*** Question G1

Le tampon d'écritures postées est un canal de communication FIFO à N cases implémenté en matériel. Il n'y a que deux opérations possibles :
- poser une donnée à une extrémité, opération accessible uniquement au composant "WBUF_FSM" (qu'on a pas encore vu, mais qu'on sait exister).
- prendre une donnée à l'autre extrémité, opération accessible uniquement au composant PIBUS_FSM.

Il n'est en particulier, dans cette configuration du cache, pas possible de consulter une donnée en plein milieu de la FIFO.

Dans le tampon, on doit stocker :
- un bit de validité
- 30 bits d'adresse
- 4 bits de byte enable
- 32 bits de données (un mot)

Si le processeur fait une requête d'écriture alors que le tampon d'écritures postées est plein, le processeur se gèle.

Si le processeur fait une requête de lecture qui fait miss alors que le tampon d'écritures postées est non-vide, le processeur se gèle jusqu'à ce que son cache lui donne la donnée, ce qui suppose que le cache (d'instructions ou de données) obtienne le bus, ce qui suppose que le tampon d'écritures postées se soit vidé au préalable.

On a ce comportement parce que les écritures sont prioritaires, et les écritures sont prioritaires pour assurer la consistance mémoire.

*** Question G2

| WBUF | Durée |  CPI | Coût écriture | Fréquence écritures |
|------+-------+------+---------------+---------------------|
|    1 | 77624 | 1.37 |          0.51 | 12.5 %              |
|    2 | 75396 | 1.33 |          0.13 | 12.5 %              |
|    4 | 74502 | 1.32 |             0 | 12.5 %              |
|    8 | 74502 | 1.32 |             0 | 12.5 %              |

Le coût des écritures, c'est le nombre de cycles de gel moyen occasionnés par une écriture.

Ce coût est très faible, parce que pour occasionner un cycle de gel, il faut remplir le tampon. Puisque la vidange du tampon est prioritaire par rapport aux lectures, le tampon d'écritures postés n'occasionne de cycle de gel que si on a un peu plus de n écritures consécutives avec n la taille du tampon. La probabilité d'avoir ces n écritures consécutives est en fait très faible (rappelons que en moyenne 10 % des instructions sont des instructions d'écriture), et diminue encore avec n augmentant.

